type: 'dino_unsupervised' # NOTE - might not need this later this way!
student_temp: 0.1
teacher_temp: 0.04
teacher_momentum_start: 0.996
teacher_momentum_final: 1
num_all_views: 8
num_global_views: 2
random_seed: 42
batch_size: 2
num_epochs: 3
warmup_initial_learning_rate: 1e-7
warmup_final_learning_rate: 1e-4
warmup_epochs: 10
lr_final: 1e-6
weight_decay: 0.001
checkpoint_dir: './checkpoints'
optimizer:
  name: AdamW
  params:
    lr: ${training.warmup_initial_learning_rate}
    weight_decay: 0.05
lr_scheduler:
  main:
    name: CosineAnnealingLR
    params:
      eta_min: 1e-6
  warmup:
    name: LinearWarmupScheduler
    params: {}