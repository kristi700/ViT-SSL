# ViT-SSL

An implementation of the Vision Transformer (ViT) in PyTorch, with a focus on understanding the architecture and exploring Self-Supervised Learning (SSL) pre-training techniques. This project aims to build a vanilla ViT from scratch and then progressively integrate methods like SimMIM and DINO.

## Overview

This repository provides a PyTorch implementation of the Vision Transformer (ViT) as described in "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale" by Dosovitskiy et al. The initial focus is on a clean and understandable implementation of the base ViT model for image classification.

The long-term goal is to extend this base with popular and effective Self-Supervised Learning (SSL) pre-training strategies, allowing the model to learn powerful representations from unlabeled image data.

## Current Features

*   **Vanilla Vision Transformer (ViT) Architecture**
*   **Supervised Training Pipeline**
*   **Evaluation & Visualization**

## Project Roadmap & Planned Features

The following features and improvements are planned for this project:

### Phase 1: Self-Supervised Pre-training - SimMIM

### Phase 2: Self-Supervised Pre-training - DINO

### Phase 3: ViT Enhancements

### Phase 4: Advanced (Future Considerations)
-   **(Potentially) DINOv2 Implementation:** Explore key components and improvements from DINOv2.
-   **Other SSL Techniques:** Investigate and potentially implement other relevant SSL methods.
